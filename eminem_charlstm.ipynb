{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q2_cfX5tcPyQ",
    "outputId": "cbbf131f-a931-4d2c-97d8-8f2bd30bd365"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,CuDNNLSTM,Bidirectional\n",
    "from keras.layers import Activation,Dropout,Flatten,GlobalMaxPool1D\n",
    "import keras.optimizers as optimizer\n",
    "\n",
    "import keras\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOnhbZsrcePl"
   },
   "outputs": [],
   "source": [
    "temp = open('./Word-Level-Lyrics-Generation/Eminem.txt',encoding = 'UTF-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "P3IILf4Gc0Bu",
    "outputId": "4cab0f75-da3f-43dc-91a2-24298e4a4f9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"spoken: \\n Oh yeah, this is Eminem baby, back up in that motherfucking ass \\n One time for your mother fucking mind, we represent the 313 \\n You know what I'm saying?, 'cause they don't know shit about this \\n For the 9-6 \\n Ayo, my pen and paper cause a \""
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dw-tJWaqdxqw"
   },
   "outputs": [],
   "source": [
    "temp = temp.lower()\n",
    "# $ =  Enter\n",
    "temp = temp.replace('\\n','$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQt55uJFfs1N"
   },
   "outputs": [],
   "source": [
    "lyrics = []\n",
    "for i,x in enumerate(temp):\n",
    "  if x == '(':\n",
    "    while(True):\n",
    "      if temp[i].strip() != ')':\n",
    "        i = i+1\n",
    "      else:\n",
    "        break\n",
    "  elif x.isdigit() or (x not in['$','?','.',' ',' \\ '] and not x.isalpha()):\n",
    "    pass\n",
    "  else:\n",
    "    lyrics.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMJITYHokLpm"
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(lyrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1l94ONTRmK1-",
    "outputId": "b991a72d-60de-4794-ef1f-addcfa846419"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "JIz3zelJozwh",
    "outputId": "be2f497c-c10e-41b2-ae54-eedb571c016a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[' ', '$', '.', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', 'á', 'â', 'ä', 'é', 'í', 'ñ', 'ó', 'ú', 'ü']\""
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU00sMW7mwaK"
   },
   "outputs": [],
   "source": [
    "intToChars = dict((i, c) for i, c in enumerate(chars))\n",
    "charsToInt = dict((i, c) for c, i in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "38danpiXn4_N"
   },
   "outputs": [],
   "source": [
    "batch = 100\n",
    "vocab_size = len(chars)\n",
    "lyrics_size = len(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mr9TjFGwoQf6"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(0,lyrics_size - batch - 1):\n",
    "  tempX = lyrics[i:(i+batch)]\n",
    "  tempY = lyrics[i+batch]\n",
    "  \n",
    "  X.append([charsToInt[ch] for ch in tempX])\n",
    "  y.append(charsToInt[tempY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r42AU0JMrAFa",
    "outputId": "c736e4cb-50ec-4424-d3e0-3090693c827e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1725300, 100, 1)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJMu4z8MOp_f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.reshape(X,(len(y),batch,1))\n",
    "y = np.reshape(y,(len(y),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ZbpG4U9vkjn"
   },
   "outputs": [],
   "source": [
    "X = X/40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsQYhis9PABq"
   },
   "outputs": [],
   "source": [
    "labels = keras.utils.to_categorical(y, num_classes=40, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NeAsUp41WbTU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQfaeP3rS-cP"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "model = Sequential()\n",
    "\n",
    "# add LSTM layer\n",
    "model.add(Bidirectional(CuDNNLSTM(128, input_shape=(batch, 1),return_sequences=True)))\n",
    "model.add(Bidirectional(CuDNNLSTM(128,return_sequences=True)))\n",
    "\n",
    "model.add(Bidirectional(CuDNNLSTM(256,return_sequences=True)))\n",
    "model.add(Bidirectional(CuDNNLSTM(256,return_sequences=True)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(100, activation=\"elu\"))\n",
    "model.add(Dropout(0.4))\n",
    "# add Softmax layer to output one character \n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "adam = optimizer.Adam(lr = 0.01)\n",
    "model.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer='Adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 854
    },
    "colab_type": "code",
    "id": "Jcx5AJt-URI2",
    "outputId": "77a8936f-b7e9-4919-ea38-33e73eb4f533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1552770 samples, validate on 172530 samples\n",
      "Epoch 1/50\n",
      "  95488/1552770 [>.............................] - ETA: 22:36 - loss: 2.7701 - acc: 0.2383"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "adam = optimizer.Adam(lr = 0.01)\n",
    "model.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer='Adam')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1,\n",
    "                              patience=1, min_lr=0.000000001)\n",
    "\n",
    "filepath=\"weights-improvement-{acc:.2f}.h5\"\n",
    "lambdac = keras.callbacks.LambdaCallback(on_epoch_begin=generate)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=3)\n",
    "callbacks_list = [reduce_lr,checkpoint,lambdac]\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=50,validation_data = (X_test,y_test),verbose = 1,callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1rRkUP_m9Y3"
   },
   "outputs": [],
   "source": [
    "def save():\n",
    "    model.save_weights('my_model_weights.h5')\n",
    "    model.save('my_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "z73iDN4dmCAn",
    "outputId": "ad0d0348-8271-4fa2-e88f-797b9b110a3e"
   },
   "outputs": [],
   "source": [
    "def generate(epoch, logs):\n",
    "    input_data = 'you can try and read my lyrics off of this paper before i lay em but you wont take the sting out the'\n",
    "    for i in range(400):  \n",
    "      temp = [charsToInt[ch] for ch in input_data]\n",
    "      temp = np.asarray(temp)\n",
    "      temp = temp.reshape((1,100,1))\n",
    "      temp = temp/40.0 \n",
    "      hum = model.predict(temp)\n",
    "      hum = np.argmax(hum)\n",
    "      ch = intToChars[hum]\n",
    "      if ch != '$':\n",
    "        sys.stdout.write(ch)\n",
    "      else:\n",
    "        print('')\n",
    "      input_data = input_data[1:]\n",
    "      input_data = input_data + ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate1():\n",
    "    input_data = 'to take a stand its '\n",
    "    for i in range(600):  \n",
    "      temp = [charsToInt[ch] for ch in input_data]\n",
    "      temp = np.asarray(temp)\n",
    "      temp = temp.reshape((1,100,1))\n",
    "      temp = temp/40.0 \n",
    "      hum = model.predict(temp)\n",
    "      hum = np.argmax(hum)\n",
    "      ch = intToChars[hum]\n",
    "      if ch != '$':\n",
    "        sys.stdout.write(ch)\n",
    "      else:\n",
    "        print('')\n",
    "      input_data = input_data[1:]\n",
    "      input_data = input_data + ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the man who would jump in front of a minivan \n",
      " since im still al inding the master \n",
      " they say i love you baby \n",
      "  \n",
      " i dont mean to be the only one \n",
      " they want me to move you more \n",
      " you should be made me \n",
      " i know you dont want it wit it \n",
      " its murda murda munda \n",
      " we aint nobody thinking that i was an armor \n",
      " i dont must be the bad guy \n",
      " i dont wanna but i gotta stay \n",
      " whoa \n",
      " is southe i constant is all over the same shit that i love you \n",
      " and you cant stop me \n",
      " i dont need you anymore \n",
      " i still be mad at a bit \n",
      " its the man they always keep a song and show your brain alone \n",
      " and i dont mean to be"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "eminem test.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
